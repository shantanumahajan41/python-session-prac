{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0a6c15-9f0a-494c-b7a1-14d57a87194f",
   "metadata": {},
   "source": [
    "# Module 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ae94f-8216-45fd-96d8-2d43c1bbb8cf",
   "metadata": {},
   "source": [
    "## Essential File Modes: Read ('r'), Write ('w'), Append ('a')\n",
    "\n",
    "1. 'r' (Read Mode): This is the default mode if no mode is explicitly specified. When a file is opened in read mode, the file pointer‚Äîan internal marker indicating the current position for reading‚Äîis placed at the very beginning of the file. If the specified file does not exist, attempting to open it in this mode will result in a FileNotFoundError. It is important to note that this mode only permits reading; writing operations are not allowed.\n",
    "2. 'w' (Write Mode): This mode opens a file exclusively for writing. A critical characteristic of 'w' mode is its behavior when the file already exists: its entire contents are truncated (erased), effectively leaving an empty file. If the file does not exist, a new, empty file is created. The file pointer is positioned at the beginning of the file, ready for new content to be written.\n",
    "3. 'a' (Append Mode): Append mode also opens a file for writing. Unlike 'w' mode, if the file already exists, its existing content is preserved. New data is written to the very end of the file, extending its content. If the file does not exist, a new, empty file is created. The file pointer is initially placed at the end of the file, ready for new additions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e53a53a-85b3-4f9a-8cf5-320774e78ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reading from a file (assuming 'my_file.txt exists)\n",
    "# Create a dummy file for demostration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee22eefb-de4c-4080-9804-df9b444f4e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content read in 'r' mode:\n",
      "This is the first line.\n",
      "This is the second line.\n"
     ]
    }
   ],
   "source": [
    "with open('my_file.txt', 'w') as f:\n",
    "    f.write('This is the first line.\\n')\n",
    "    f.write('This is the second line.')\n",
    "\n",
    "file = open('my_file.txt', 'r')\n",
    "content = file.read()\n",
    "print(\"Content read in 'r' mode:\")\n",
    "print(content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3b7184-8106-4fb5-a699-1a8c0b431964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Content after writing in 'w' mode:\n",
      "Hello, Python File Handling!\n"
     ]
    }
   ],
   "source": [
    "# Example: Writing to a file (will overwrite if 'my_file.txt' exists)\n",
    "file = open('my_file.txt', 'w')\n",
    "file.write('Hello, Python File Handling!')\n",
    "file.close()\n",
    "print(\"\\nContent after writing in 'w' mode:\")\n",
    "with open('my_file.txt', 'r') as f:\n",
    "   print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ba49d6-d833-4813-a01d-9a7a12722df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Content after appending in 'a' mode:\n",
      "Hello, Python File Handling!\n",
      "This line is appended.\n"
     ]
    }
   ],
   "source": [
    "# Example: Appending to a file\n",
    "file = open('my_file.txt', 'a')\n",
    "file.write('\\nThis line is appended.')\n",
    "file.close()\n",
    "print(\"\\nContent after appending in 'a' mode:\")\n",
    "with open('my_file.txt', 'r') as f:\n",
    "   print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88825140-ffa5-4345-b389-4cbcb77ca2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c2e68b-43bd-473a-8c1b-fea5da216187",
   "metadata": {},
   "source": [
    "## Combined Modes ('r+', 'w+', 'a+')\n",
    "\n",
    "The '+' modifier can be combined with the primary modes ('r', 'w', or 'a') to enable both reading and writing operations on the file.\n",
    "\n",
    "1. 'r+' (Read and Write): This mode opens the file for both reading and writing. The file pointer is initially at the beginning. If the file does not exist, a FileNotFoundError is raised. Crucially, existing content is not truncated, allowing for modifications within the file.\n",
    "2. 'w+' (Write and Read): This mode opens the file for both writing and reading. If the file exists, its contents are truncated (erased), just like in 'w' mode. If the file does not exist, a new file is created. The file pointer is at the beginning.\n",
    "3. 'a+' (Append and Read): This mode opens the file for both appending and reading. The file pointer is initially at the end of the file for writing new data. However, the pointer can be explicitly moved using seek() (discussed in Module 5) to read from other positions within the file. If the file does not exist, a new file is created.\n",
    "\n",
    "A significant point of caution arises when using 'w' and 'w+' modes. These modes inherently carry a risk of silent data loss. Accidentally opening an existing and important file in either 'w' or 'w+' mode will immediately wipe out its entire contents without any warning or confirmation from Python. This behavior makes it imperative to implement robust error handling and to proactively check for file existence before performing any write operations, a topic that will be covered in detail in Module 4 and Module 8. Developers must be acutely aware of this truncation behavior to prevent unintended data destruction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c04600-579e-49a3-a04a-d461a5895545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81f64380-c506-4157-bcc1-5ae067e00318",
   "metadata": {},
   "source": [
    "## Binary Mode ('b')\n",
    "The 'b' modifier is used to open files in binary mode. This mode is specifically for handling non-human-readable files, such as images, audio files, compiled programs, or encrypted data. When a file is opened in binary mode, data is read and written as bytes objects rather than standard strings. This mode is always combined with other primary modes, forming combinations like 'rb' (read binary) or 'wb' (write binary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320cc618-08a0-480a-8d81-e8f4e1fcf974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binary data written to 'example.bin': b'\\x00\\xff\\x00\\xff\\x1a\\n'\n",
      "Binary data read from 'example.bin': b'\\x00\\xff\\x00\\xff\\x1a\\n'\n"
     ]
    }
   ],
   "source": [
    "# Example: Writing and reading binary data\n",
    "# A simple byte sequence representing some arbitrary binary data\n",
    "binary_data_to_write = b'\\x00\\xFF\\x00\\xFF\\x1A\\x0A'\n",
    "with open('example.bin', 'wb') as f:\n",
    "   f.write(binary_data_to_write)\n",
    "print(f\"\\nBinary data written to 'example.bin': {binary_data_to_write}\")\n",
    "\n",
    "with open('example.bin', 'rb') as f:\n",
    "   data = f.read()\n",
    "   print(f\"Binary data read from 'example.bin': {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c15e2-c193-4d53-99be-c5aff0115bc7",
   "metadata": {},
   "source": [
    "## The Critical Step: Closing Files with file.close()\n",
    "After all operations on a file are completed, it is absolutely essential to close it using the file.close() method. This action is not merely a formality; it is a critical step that releases the system resources that the operating system allocated for your program to access that file. These resources are often referred to as \"file handles\" on Windows or \"file descriptors\" on Unix-like systems (including Linux and macOS).\n",
    "\n",
    "Failing to close files can lead to several detrimental consequences:\n",
    "\n",
    "    Data Corruption: Unsaved changes that are still buffered in memory might not be written to the physical disk, leading to incomplete or corrupted data.\n",
    "    Resource Leaks: Your program might continue to hold onto system resources unnecessarily. Each open file consumes a file descriptor, and operating systems have limits on how many descriptors a single process can hold. Exhausting these limits can lead to performance degradation or prevent your program, or even other applications, from opening new files.\n",
    "    File Locking: On some operating systems, an open file might remain locked, preventing other processes or even subsequent attempts by your own program from accessing or modifying it.\n",
    "\n",
    "The underlying mechanism for file handling involves Python making system calls to the operating system. When open() is invoked, the OS locates the file and returns an integer identifier (the file handle/descriptor). This identifier is then used for all subsequent read, write, or close operations. Therefore, closing a file is not just a Python-specific instruction; it is a direct command to the operating system to release a valuable, limited resource. This concept extends beyond files to other system resources like network sockets or database connections, underscoring the broader importance of resource management, which is elegantly addressed by context managers (Module 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb072a-164c-4d13-a14f-0d0121682512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032e3fc-88bb-4cc8-a119-66a8118919ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abf35381-2804-4b90-8731-5d589afc29c3",
   "metadata": {},
   "source": [
    "# Module 2: Reading and Writing Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceba1be-cf49-41e4-817a-dbeaa3e4f79c",
   "metadata": {},
   "source": [
    "Once a file is successfully opened, the next step involves interacting with its content. This module explores the various methods Python provides for reading data from text files and writing new content to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f98836-d762-44ad-855d-6285a44d2c91",
   "metadata": {},
   "source": [
    "## Reading Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f438222-e771-4b9e-8a88-3256eef7dde0",
   "metadata": {},
   "source": [
    "Python offers several methods to retrieve data from an opened file object, each suited for different scenarios and file sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f571e76-852a-49dc-8611-088f80f67cc5",
   "metadata": {},
   "source": [
    "### read(): Grabbing the Whole Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37c756-cac4-4d8f-83c5-e35548d68f1e",
   "metadata": {},
   "source": [
    "The read() method is designed to read the entire content of a file and return it as a single string. This is convenient for smaller files where loading the entire content into memory is not an issue. An optional integer argument, size, can be passed to read() to specify the number of characters (or bytes in binary mode) to read from the current file pointer position. If size is omitted or provided as a negative value, the method reads the entire remaining content of the file from the current pointer position until the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c442ef5-dcd7-41dc-af74-f06cec8519e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Full Content ---\n",
      "Line 1: Hello World!\n",
      "Line 2: Python is fun.\n",
      "Line 3: File handling basics.\n",
      "\n",
      "--- Partial Content (10 chars) ---\n",
      "Line 1: He\n"
     ]
    }
   ],
   "source": [
    "# Create a sample file for demonstration\n",
    "with open('sample.txt', 'w') as f:\n",
    "   f.write('Line 1: Hello World!\\n')\n",
    "   f.write('Line 2: Python is fun.\\n')\n",
    "   f.write('Line 3: File handling basics.')\n",
    "\n",
    "# Read the entire file\n",
    "with open('sample.txt', 'r') as f:\n",
    "   content = f.read()\n",
    "   print(\"--- Full Content ---\")\n",
    "   print(content)\n",
    "\n",
    "# Read a specific number of characters\n",
    "with open('sample.txt', 'r') as f:\n",
    "   partial_content = f.read(10) # Reads first 10 characters\n",
    "   print(\"\\n--- Partial Content (10 chars) ---\")\n",
    "   print(partial_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ea40c-b589-4765-b92f-cd231b10511b",
   "metadata": {},
   "source": [
    "### readline(): Processing Line by Line (Efficient for Large Files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a009e53-ad64-4022-8262-d823f693b01a",
   "metadata": {},
   "source": [
    "The readline() method reads a single line from the file at a time, including the newline character (\\n) at the end of the line. When the end of the file is reached, readline() returns an empty string (''). This method is particularly valuable for processing very large files because it avoids loading the entire file into memory simultaneously, thereby conserving system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf3a06c-6b6c-43ba-a50a-56cd9f4c8530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reading Line by Line ---\n",
      "Line 1: Hello World!\n",
      "Line 2: Python is fun.\n",
      "\n",
      "--- Looping Line by Line ---\n",
      "Line 1: Hello World!\n",
      "Line 2: Python is fun.\n",
      "Line 3: File handling basics."
     ]
    }
   ],
   "source": [
    "# Read line by line\n",
    "with open('sample.txt', 'r') as f:\n",
    "   print(\"\\n--- Reading Line by Line ---\")\n",
    "   line1 = f.readline()\n",
    "   print(line1, end='') # Use end='' to avoid double newline\n",
    "   line2 = f.readline()\n",
    "   print(line2, end='')\n",
    "   # Demonstrate looping through lines\n",
    "   print(\"\\n--- Looping Line by Line ---\")\n",
    "   f.seek(0) # Reset pointer to beginning to re-read\n",
    "   line = f.readline()\n",
    "   while line:\n",
    "       print(line, end='')\n",
    "       line = f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73c2bf-a5a2-49bd-a7fe-452f2f753c49",
   "metadata": {},
   "source": [
    "### readlines(): Getting All Lines as a List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abff34-54ba-4a9f-9639-fc80bd0a9110",
   "metadata": {},
   "source": [
    "The readlines() method reads all remaining lines from the file from the current file pointer position until the end of the file. It then returns these lines as a list of strings, where each string in the list represents a line from the file and includes its respective newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d14f33f-ebc2-4da6-bc17-0f1e2cc01fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- All Lines as List ---\n",
      "Line 1: Hello World!\n",
      "Line 2: Python is fun.\n",
      "Line 3: File handling basics."
     ]
    }
   ],
   "source": [
    "# Read all lines into a list\n",
    "with open('sample.txt', 'r') as f:\n",
    "   lines = f.readlines()\n",
    "   print(\"\\n--- All Lines as List ---\")\n",
    "   for line in lines:\n",
    "       print(line, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9826c07-e4c9-44c2-a500-867b12c0296e",
   "metadata": {},
   "source": [
    "When choosing a reading strategy, it is important to consider memory efficiency and performance. While read() and readlines() offer convenience by loading entire file contents into RAM, this approach can quickly become problematic for files that are gigabytes in size, potentially leading to a MemoryError or significantly slowing down program execution. For processing large text files, the most memory-efficient method involves iterating directly over the file object itself (e.g., for line in file_object:). This implicit iteration leverages readline() internally, processing data one line at a time without holding the entire file in memory. This distinction is crucial for developing scalable applications capable of handling substantial datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e5678-b70d-4d81-958e-d5662313206d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd310ef3-47c0-4c56-b935-d0d2b78482c9",
   "metadata": {},
   "source": [
    "## Writing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5357f0-7532-46a7-a3ee-814e71b229d7",
   "metadata": {},
   "source": [
    "Python provides methods to write string data to an opened file object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c99ce-c004-47aa-9f66-126084762bc0",
   "metadata": {},
   "source": [
    "### write(): Adding Text to Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab73b4-6d23-4ef9-8751-2dcd4737e588",
   "metadata": {},
   "source": [
    "The write() method is used to write a string to the file at the current position of the file pointer. It returns the number of characters (or bytes in binary mode) that were successfully written. A key characteristic of write() is that it does not automatically append a newline character (\\n) at the end of the string. If a line break is desired, it must be explicitly included within the string being written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917d2e16-8162-4243-be50-2179ea06e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Content of output.txt after writing ---\n",
      "First line of text.\n",
      "Second line of text.\n"
     ]
    }
   ],
   "source": [
    "# Writing to a file (overwrites existing content if in 'w' mode)\n",
    "with open('output.txt', 'w') as f:\n",
    "   f.write('First line of text.\\n')\n",
    "   f.write('Second line of text.')\n",
    "print(\"\\n--- Content of output.txt after writing ---\")\n",
    "with open('output.txt', 'r') as f:\n",
    "   print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a0c5e-c177-49f8-92f5-d8376b8ff883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0364629-0362-4a02-b50a-40c30618f4c1",
   "metadata": {},
   "source": [
    "### writelines(): Writing Multiple Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fe5bb-4dc2-4d05-9a27-8a3b079518b7",
   "metadata": {},
   "source": [
    "The writelines() method is designed to write a sequence of strings (such as a list or tuple of strings) to the file. It is crucial to understand that writelines() does not automatically add line endings (\\n) to each item in the sequence. The responsibility for including the appropriate newline characters within each string in the sequence falls entirely on the developer if they wish for the content to appear on separate lines in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a546b833-f142-4a7b-9b0a-3ae6eb0314bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Content of output.txt after appending with writelines ---\n",
      "First line of text.\n",
      "Second line of text.\n",
      "Third line of text.\n",
      "Fourth line of text.\n"
     ]
    }
   ],
   "source": [
    "# Writing multiple lines from a list\n",
    "lines_to_write = ['\\nThird line of text.\\n','Fourth line of text.'] \n",
    "with open('output.txt', 'a') as f: # Using 'a' to append to existing content\n",
    "   f.writelines(lines_to_write)\n",
    "print(\"\\n--- Content of output.txt after appending with writelines ---\")\n",
    "with open('output.txt', 'r') as f:\n",
    "   print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25d2da-5ab0-40df-a52c-b34c612dd883",
   "metadata": {},
   "source": [
    "A common pitfall for beginners using write() and writelines() is the expectation that these methods behave like the print() function, which automatically adds a newline character by default. However, this is not the case for file writing methods. Forgetting to explicitly include \\n characters within the strings being written will result in all text being concatenated into a single, continuous, and often unreadable line within the output file. This detail significantly impacts the readability and subsequent parsability of the generated files, potentially disrupting downstream processing or human review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63633548-ad47-4712-be04-baab4791b7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bf2b8-2b32-4d18-8b43-10954367e958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e732185-4c42-4678-96c0-58ed0f9c34e8",
   "metadata": {},
   "source": [
    "# Module 3: The with Statement and Context Managers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67e6d0-d597-47eb-968a-0e6dbd2b72cf",
   "metadata": {},
   "source": [
    "This module introduces the most Pythonic and highly recommended approach to file handling: the with statement. It is a cornerstone of writing robust and reliable Python code, particularly when dealing with external resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaadb3d3-fb3b-4f01-be8f-5c7afd304c73",
   "metadata": {},
   "source": [
    "## The Pythonic Way: Why with open(...) is Superior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000325cb-35fa-4101-9eae-9e7a35ade32b",
   "metadata": {},
   "source": [
    "While manually calling open() to acquire a file object and close() to release it is functional, this approach is inherently susceptible to errors. If an exception occurs during file operations‚Äîbetween the open() call and the close() call‚Äîthe close() method might never be executed, leading to resource leaks and potential data corruption. The with statement, formally introduced in Python Enhancement Proposal (PEP) 343, provides a cleaner, safer, and more readable alternative for managing resources like files. It automatically handles both the setup (acquiring the resource, such as opening a file) and teardown (releasing the resource, such as closing the file) phases, guaranteeing that cleanup occurs even if the code encounters an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75afa18-6135-44e4-93ff-234b5c957719",
   "metadata": {},
   "source": [
    "## Automatic Resource Management: No More Forgotten close() Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b6855b-eb05-4efe-8258-9705970495b2",
   "metadata": {},
   "source": [
    "The primary and most significant advantage of using the with open(...) as file: construct is its guarantee that the file will be closed automatically once the indented block of code is exited. This closure occurs regardless of whether the block finishes normally or terminates prematurely due to an exception. This automatic resource management prevents common issues such as resource leaks (where file handles remain open indefinitely), ensures data integrity by flushing buffered changes to disk, and significantly simplifies the codebase by eliminating the need for explicit try...finally blocks dedicated solely to cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f58f45-56e4-4daa-a602-0a307b80979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'example_with.txt' created and automatically closed.\n",
      "Caught an error, but the file (if it existed) would be closed.\n"
     ]
    }
   ],
   "source": [
    "# Example: Using the with statement for writing\n",
    "with open('example_with.txt', 'w') as file:\n",
    "   file.write('This text is written using the with statement.')\n",
    "   # No need to call file.close() explicitly!\n",
    "print(\"File 'example_with.txt' created and automatically closed.\")\n",
    "\n",
    "# Example with error handling (still closes automatically)\n",
    "try:\n",
    "   with open('non_existent_file.txt', 'r') as file: # This file does not exist\n",
    "       content = file.read()\n",
    "       print(content)\n",
    "except FileNotFoundError:\n",
    "   print(\"Caught an error, but the file (if it existed) would be closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f739b-f409-4155-bf24-725d8cf6284a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "825b6f06-059f-42f5-ad1e-a1f228e9979d",
   "metadata": {},
   "source": [
    "## A Glimpse Under the Hood: __enter__ and __exit__ (Simplified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84503124-e057-49ad-b52a-65f75983a0a8",
   "metadata": {},
   "source": [
    "The with statement's power stems from its interaction with \"context manager\" objects. Any object that is designed to be used with a with statement must implement two special methods, often referred to as \"dunder\" (double underscore) methods:\n",
    "\n",
    "    __enter__(self): This method is invoked when the execution flow first enters the with block. Its primary role is to perform any necessary setup or resource acquisition (e.g., opening a file, establishing a database connection). It typically returns the resource object itself (e.g., the opened file object), which is then bound to the variable specified after the as keyword in the with statement.\n",
    "    __exit__(self, exc_type, exc_value, exc_tb): This method is called when the execution flow leaves the with block, irrespective of whether the block completed successfully or terminated due to an exception. Its purpose is to perform any necessary cleanup or resource release (e.g., closing the file, committing database changes). The exc_type, exc_value, and exc_tb arguments provide detailed information about any exception that might have occurred within the with block. If __exit__ returns a True value, it indicates that the context manager has successfully handled and suppressed the exception, allowing execution to continue as if no error occurred. Conversely, if it returns False (or implicitly None, which is the default), the exception is re-raised and propagated outside the context manager.\n",
    "\n",
    "The with statement, and the underlying concept of context managers, represents a powerful design pattern in Python for managing any resource that requires a defined setup and teardown procedure. This extends far beyond simple file handling to encompass a wide array of scenarios, such as managing network connections, database sessions, or even acquiring and releasing locks in concurrent programming. By abstracting away the boilerplate code for resource acquisition and release, context managers make code significantly cleaner, more readable, and inherently more robust. Understanding this pattern is crucial for interacting with many other Python libraries that leverage context managers, such as sqlite3.connect for database access or threading.Lock for managing shared resources in multi-threaded applications.\n",
    "\n",
    "A subtle yet powerful aspect of the __exit__ method lies in its ability to suppress exceptions. While with statements are generally understood to automatically close resources, the detailed mechanism reveals that if __exit__() returns True, any exception that occurred within the with block is effectively \"swallowed\" or suppressed. This means a context manager can internally handle an error and allow the program to proceed as if no error had occurred. Although this capability offers immense power and flexibility in designing custom resource management, it must be approached with extreme caution. A context manager that silently suppresses critical errors without proper logging or alternative handling can make debugging incredibly challenging, as the root cause of an issue might be obscured. This underscores the importance of thoughtful context manager design and transparent error reporting in professional software development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ace238-8042-439c-bdff-cffda3671314",
   "metadata": {},
   "source": [
    "## Refactoring Examples with with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810fc73-2060-4e17-813a-5c0e0221d224",
   "metadata": {},
   "source": [
    "To illustrate the benefits, consider refactoring the basic file reading and writing examples from Module 2 using the with statement. The reduction in boilerplate code and the inherent safety improvements become immediately apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb34181-ceee-4ae9-9f48-d0da034ac0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Refactored Read Example with 'with' ---\n",
      "Line 1: Hello World!\n",
      "Line 2: Python is fun.\n",
      "Line 3: File handling basics.\n",
      "\n",
      "--- Refactored Write Example with 'with' ---\n",
      "File 'output_refactored.txt' created and automatically closed.\n"
     ]
    }
   ],
   "source": [
    "# Original example (Module 2, read())\n",
    "# file = open('sample.txt', 'r')\n",
    "# content = file.read()\n",
    "# print(content)\n",
    "# file.close()\n",
    "\n",
    "# Refactored with 'with' statement\n",
    "print(\"\\n--- Refactored Read Example with 'with' ---\")\n",
    "with open('sample.txt', 'r') as file:\n",
    "   content = file.read()\n",
    "   print(content)\n",
    "# File is automatically closed here\n",
    "\n",
    "# Original example (Module 2, write())\n",
    "# file = open('output.txt', 'w')\n",
    "# file.write('First line of text.\\n')\n",
    "# file.write('Second line of text.')\n",
    "# file.close()\n",
    "\n",
    "# Refactored with 'with' statement\n",
    "print(\"\\n--- Refactored Write Example with 'with' ---\")\n",
    "with open('output_refactored.txt', 'w') as file:\n",
    "   file.write('This is the first line from refactored write.\\n')\n",
    "   file.write('This is the second line from refactored write.')\n",
    "# File is automatically closed here\n",
    "print(\"File 'output_refactored.txt' created and automatically closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00304e-0b3b-4697-a702-fd37e47f78c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "849b4220-501f-43cf-be4f-6d3094e8ea0d",
   "metadata": {},
   "source": [
    "# Module 4: Robust File Handling: Error Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a26a2f3-823c-4027-94d2-0a1f71d0dc51",
   "metadata": {},
   "source": [
    "Despite the advantages of the with statement, file operations are inherently susceptible to failures caused by external factors beyond a program's direct control. Files might be missing, access permissions could be denied, or the storage device might be full. Consequently, implementing robust error handling is not merely a good practice but an essential requirement for building reliable and resilient applications. Python signals these issues by raising exceptions, which can then be caught and managed gracefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd466800-0d76-40d8-bab8-0383b46dc281",
   "metadata": {},
   "source": [
    "## Anticipating Problems: Common File-Related Exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d2549-86d3-468c-adbe-c2a2eddbf302",
   "metadata": {},
   "source": [
    "Understanding the specific types of exceptions that can occur during file operations is the first step toward effective error management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94066f12-ebdb-463f-a9b7-9b661a70f616",
   "metadata": {},
   "source": [
    "1. FileNotFoundError: This is one of the most frequently encountered file-related exceptions. It is raised when a program attempts to open, read from, or write to a file that simply does not exist at the specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e0a12c8-8257-47aa-a92d-e893e9ca7a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file you tried to open does not exist. Please verify the path.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   with open('non_existent_file.txt', 'r') as file:\n",
    "       content = file.read()\n",
    "except FileNotFoundError:\n",
    "   print(\"Error: The file you tried to open does not exist. Please verify the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4af483c-3b6f-4a0f-a9c3-2d637c4a43e1",
   "metadata": {},
   "source": [
    "2. PermissionError: This exception occurs when a program attempts to perform an operation (such as reading, writing, or deleting) on a file or directory for which it lacks the necessary operating system permissions. For instance, trying to write to a protected system file without administrative privileges would typically raise this error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3154cd-acab-43fc-9f3d-445f6190562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: [Errno 22] Invalid argument: 'C:\\\\Windows\\\\Microsoft\\text.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\shant\\AppData\\Local\\Temp\\ipykernel_8048\\4135058705.py:5: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  with open('C:\\Windows\\Microsoft\\text.txt', 'w') as file:\n"
     ]
    }
   ],
   "source": [
    "# This example might require specific file permissions or OS setup to trigger\n",
    "# On a Unix-like system, try writing to a protected directory like '/root/test.txt' without sudo\n",
    "try:\n",
    "   # Attempt to write to a path that typically requires elevated permissions\n",
    "   with open('C:\\Windows\\Microsoft\\text.txt', 'w') as file:\n",
    "       file.write(\"Attempting to write sensitive data.\")\n",
    "except PermissionError:\n",
    "   print(\"Error: You do not have sufficient permissions to access or modify this file.\")\n",
    "except Exception as e: # Catch other potential errors if the file doesn't exist etc.\n",
    "   print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2acc4-5d15-45c5-81f7-e5c480f1a567",
   "metadata": {},
   "source": [
    "3. IsADirectoryError: This exception is raised when a program attempts to open a path that points to a directory as if it were a regular file. For example, if my_folder is an existing directory, open('my_folder', 'r') would result in an IsADirectoryError.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397cad89-d65a-4f59-bccf-3aad4944e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('my_new_directory', exist_ok=True) # Ensure directory exists\n",
    "try:\n",
    "   with open('my_new_directory', 'r') as file: # Trying to open a directory as a file\n",
    "       content = file.read()\n",
    "except IsADirectoryError:\n",
    "   print(\"Error: The path specified is a directory, not a file. Please provide a file path.\")\n",
    "finally:\n",
    "   # Clean up the created directory for subsequent runs\n",
    "   if os.path.exists('my_new_directory') and os.path.isdir('my_new_directory'):\n",
    "       os.rmdir('my_new_directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910be49-c805-4464-93db-f1baf5d57c8b",
   "metadata": {},
   "source": [
    "4. IOError / OSError: IOError is a broad category for general input/output errors. In modern Python, specific file-related exceptions like FileNotFoundError, PermissionError, and IsADirectoryError are all subclasses of OSError. Catching OSError can serve as a more general catch-all for various operating system-related problems encountered during file operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ec0934d-e8b1-4e22-b67d-b6c6a131eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An operating system error occurred during file access: [Errno 2] No such file or directory: 'potentially_problematic_file.txt'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   # This could potentially raise FileNotFoundError, PermissionError, IsADirectoryError, etc.\n",
    "   with open('potentially_problematic_file.txt', 'r') as file:\n",
    "       content = file.read()\n",
    "except OSError as e: # Catches any OS-related error\n",
    "   print(f\"An operating system error occurred during file access: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd1ccf-e546-4885-beb9-cd4ce29eb9ce",
   "metadata": {},
   "source": [
    "    The relationship between specific file exceptions and the broader OSError base class is an important aspect of Python's exception hierarchy. While FileNotFoundError, PermissionError, and IsADirectoryError offer highly specific details about the nature of a file system problem, allowing for tailored error messages and recovery actions, they all derive from the more general OSError. This hierarchical structure means that catching OSError can simplify except blocks if the goal is to handle any general file system issue without needing to distinguish the exact cause. However, a more refined approach, often considered a best practice, involves catching the most specific exceptions first, followed by more general ones. This strategy enables more precise debugging, allows for distinct responses to different error conditions, and provides clearer feedback to the user or system logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a3ba78-3a37-45bd-bac4-b17311783a02",
   "metadata": {},
   "source": [
    "## Implementing try-except Blocks for Graceful Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d94f5e-71f9-4d97-9b7d-da848db29c59",
   "metadata": {},
   "source": [
    "The try-except block is Python's fundamental construct for handling exceptions gracefully. It allows a program to anticipate and respond to potential errors without crashing.\n",
    "\n",
    "    1. The try block encloses the code that might raise an exception.\n",
    "    2. One or more except blocks follow, each designed to catch and handle a specific type of exception.\n",
    "    3. An optional else block can be included; its code executes only if no exception occurs within the try block.\n",
    "    4. An optional finally block, if present, executes unconditionally, regardless of whether an exception occurred or not. While the with statement is the preferred method for ensuring file closure, the finally block remains useful for other cleanup tasks that must always run (e.g., releasing non-file resources, logging completion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5419111-5450-412f-bede-24435c4850fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content: This is important data.\n",
      "Successfully read 'important_data.txt'. No exceptions were raised.\n",
      "File operation attempt finished. Cleaning up dummy file.\n"
     ]
    }
   ],
   "source": [
    "file_name = 'important_data.txt'\n",
    "# Create a dummy file for demonstration of success path\n",
    "with open(file_name, 'w') as f:\n",
    "   f.write(\"This is important data.\")\n",
    "\n",
    "try:\n",
    "   with open(file_name, 'r') as f:\n",
    "       content = f.read()\n",
    "       print(f\"File content: {content}\")\n",
    "except FileNotFoundError:\n",
    "   print(f\"Error: '{file_name}' was not found. Please check the path.\")\n",
    "except PermissionError:\n",
    "   print(f\"Error: You don't have permission to read '{file_name}'.\")\n",
    "except OSError as e: # Catch any other OS-related errors\n",
    "   print(f\"An unexpected OS error occurred with '{file_name}': {e}\")\n",
    "else:\n",
    "   print(f\"Successfully read '{file_name}'. No exceptions were raised.\")\n",
    "finally:\n",
    "   print(\"File operation attempt finished. Cleaning up dummy file.\")\n",
    "   if os.path.exists(file_name):\n",
    "       os.remove(file_name) # Clean up the dummy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cfbaa-f728-4d62-932d-bfd2bbe5b5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d50ed5f-6881-4a65-a52a-52d5be4383da",
   "metadata": {},
   "source": [
    "## Best Practices for Error Handling in File Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d026a-c38c-4688-9df7-753bb96c6682",
   "metadata": {},
   "source": [
    "To build robust and reliable applications that interact with the file system, adhering to certain best practices for error handling is crucial:\n",
    "\n",
    "   1. Always Use Context Managers (with statement): This is the foremost best practice. Employing with open(...) ensures that files are automatically and properly closed, even if errors occur within the code block. This serves as the primary defense against resource leaks and helps maintain data integrity.\n",
    "   2. Catch Specific Exceptions First: When structuring try-except blocks, it is advisable to list the most specific exceptions (e.g., FileNotFoundError, PermissionError) before more general ones (e.g., OSError, Exception). This allows for more targeted error messages, enables specific recovery actions, and improves the clarity of your error handling logic.\n",
    "   3. Log Errors for Debugging: Instead of merely printing error messages to the console, consider implementing a logging mechanism. Logging detailed error information, including the exception type, message, and traceback, is invaluable for debugging and diagnosing issues in production environments.\n",
    "   4. Proactive File Existence Checks: For read operations, it is often beneficial to proactively check if a file exists using os.path.exists() (covered in Module 8) before attempting to open it. This allows for a more graceful pre-check and can prevent a FileNotFoundError from being raised in the first place. This approach provides an opportunity to inform the user or take alternative action before an exception disrupts the program flow.\n",
    "\n",
    "The distinction between proactive and reactive error handling is a key strategic consideration in software development. While try-except blocks are essential for reactively catching and handling exceptions after they have occurred, truly robust error management also involves anticipating common problems and preventing them before they even arise. For instance, using os.path.exists() to verify a file's presence before attempting to open it in read mode is a proactive measure. This allows a program to provide more user-friendly feedback, suggest corrective actions, or gracefully adjust its behavior without relying solely on the Python interpreter to raise an exception. Combining reactive exception handling with proactive checks leads to more resilient and user-friendly applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c4af1-0add-4fc2-aa34-afd535149bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5b81cd3-6a83-4829-b357-ef72e831b7ce",
   "metadata": {},
   "source": [
    "# Module 5: Advanced Text File Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863ea12-7126-4f0b-8c12-7121a0c4e74a",
   "metadata": {},
   "source": [
    "Beyond the fundamental operations of reading and writing, a deeper understanding of character encoding and file positioning provides finer-grained control over how text files are handled and interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e92d96-0741-4217-913f-4923118a3945",
   "metadata": {},
   "source": [
    "## Character Encoding: The encoding Parameter and UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fb3296-0edc-48f7-84f6-5665f0fe96a7",
   "metadata": {},
   "source": [
    "When text is stored or transmitted, computers do not directly store characters like 'A' or 'œÄ'. Instead, they store numerical representations. Character encoding is the standardized system that maps these numbers to specific characters. If a file is read using an encoding different from the one it was written with, the result can be garbled text (known as \"mojibake\") or, more commonly, a UnicodeDecodeError.\n",
    "\n",
    "UTF-8 (Unicode Transformation Format - 8-bit) is the most widely adopted and recommended character encoding standard in modern computing. Its popularity stems from its ability to support virtually all characters and symbols from every language worldwide, making it highly versatile. Furthermore, it is backward-compatible with ASCII, meaning standard English text encoded in ASCII is also valid UTF-8. Python 3 provides native and robust support for UTF-8.\n",
    "\n",
    "To prevent the common UnicodeDecodeError, it is a strong practice to explicitly specify encoding='utf-8' when opening text files using the open() function. By default, open() might rely on the system's default encoding, which can vary across different operating systems or user configurations, leading to inconsistencies and errors when sharing files or running code in different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e8c4b11-5695-4033-9298-a2f38b5efc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text written to 'unicode_example.txt' (UTF-8): 'Hello, ‰∏ñÁïå! „Åì„Çì„Å´„Å°„ÅØ! üòä This is a test.'\n",
      "Read with UTF-8 encoding: 'Hello, ‰∏ñÁïå! „Åì„Çì„Å´„Å°„ÅØ! üòä This is a test.'\n",
      "\n",
      "Caught UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 7: ordinal not in range(128)\n",
      "This error occurs when trying to decode characters (like '‰∏ñÁïå' or 'üòä') that are not representable in the 'ascii' encoding using the 'ascii' codec.\n"
     ]
    }
   ],
   "source": [
    "# Example: Writing and reading with UTF-8 encoding\n",
    "text_with_special_chars = \"Hello, ‰∏ñÁïå! „Åì„Çì„Å´„Å°„ÅØ! üòä This is a test.\"\n",
    "with open('unicode_example.txt', 'w', encoding='utf-8') as f:\n",
    "   f.write(text_with_special_chars)\n",
    "print(f\"Text written to 'unicode_example.txt' (UTF-8): '{text_with_special_chars}'\")\n",
    "\n",
    "with open('unicode_example.txt', 'r', encoding='utf-8') as f:\n",
    "   content = f.read()\n",
    "   print(f\"Read with UTF-8 encoding: '{content}'\")\n",
    "\n",
    "# Example of potential UnicodeDecodeError (if file was saved as UTF-8 but read as ASCII)\n",
    "try:\n",
    "   with open('unicode_example.txt', 'r', encoding='ascii') as f:\n",
    "       content_ascii = f.read()\n",
    "       print(f\"Attempted to read with ASCII encoding: '{content_ascii}'\")\n",
    "except UnicodeDecodeError as e:\n",
    "   print(f\"\\nCaught UnicodeDecodeError: {e}\")\n",
    "   print(\"This error occurs when trying to decode characters (like '‰∏ñÁïå' or 'üòä') that are not representable in the 'ascii' encoding using the 'ascii' codec.\")\n",
    "\n",
    "# Clean up the dummy file\n",
    "if os.path.exists('unicode_example.txt'):\n",
    "   os.remove('unicode_example.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da978734-0a47-44f6-9707-8b19f13fb042",
   "metadata": {},
   "source": [
    "The global nature of data and the importance of character encoding are critical considerations in modern software development. In today's interconnected world, applications frequently encounter text that extends beyond the basic English alphabet. Names, addresses, and content can originate from various languages and scripts. Assuming a default encoding, which might be ASCII or a regional standard (e.g., Latin-1), can lead to frustrating UnicodeDecodeError exceptions or, more insidiously, silent data corruption where characters are misinterpreted without an explicit error. Explicitly using UTF-8 is not merely a recommended practice; it is a professional necessity for building applications that are truly global-ready, ensuring that text from diverse linguistic backgrounds is handled consistently and correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183106c7-08c2-451c-b67f-a1be30500d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ccb1e3-9a12-4313-8839-77ab9c263ce9",
   "metadata": {},
   "source": [
    "## Navigating Files: seek() and tell()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee66343-550a-4c08-b8a1-0ec3c6aa32e9",
   "metadata": {},
   "source": [
    "When a file is opened for reading or writing, Python maintains an internal \"file pointer\" (often conceptualized as a cursor) that indicates the current position within the file where the next read or write operation will occur. The seek() and tell() methods provide direct control and query capabilities over this pointer, enabling non-sequential access to file content.\n",
    "\n",
    "   ** tell(): This method returns an integer representing the current position of the file pointer within the file. The position is measured in bytes from the beginning of the file.\n",
    "    seek(offset, whence=0): This method changes the current position of the file pointer.\n",
    "\n",
    "   ** offset: This is the number of bytes to move the pointer. It can be positive (to move forward) or negative (to move backward).\n",
    "    whence: This is an optional argument that specifies the reference point for the offset. It can take one of three integer values, often accessed via the os module constants:\n",
    "\n",
    "           * 0 (or os.SEEK_SET): This is the default. The offset is relative to the beginning of the file.\n",
    "           * 1 (or os.SEEK_CUR): The offset is relative to the current position of the file pointer.\n",
    "           * 2 (or os.SEEK_END): The offset is relative to the end of the file. When using this whence, the offset is typically negative to move backward from the end.\n",
    "\n",
    "It is important to note that when working with text files (not binary files), using seek() with whence values other than os.SEEK_SET (0) can be unreliable due to the complexities of character encoding. For precise byte-level seeking, especially with variable-length encodings like UTF-8, it is generally recommended to open the file in binary mode ('b')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ef78172-0534-4962-9be0-920d12c0a256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of 'seek_tell_example.txt': '0123456789abcdefghijklmnopqrstuvwxyz'\n",
      "Initial position: 0\n",
      "Read: '01234', Current position: 5\n",
      "Seek to 10, Read: 'abcde', Current position: 15\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextIOWrapper.seek() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m content2 = f.read(\u001b[32m5\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeek to 10, Read: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, Current position: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.tell()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# Output: 'abcde', 15\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhence\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSEEK_END\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Move 10 bytes back from the end\u001b[39;00m\n\u001b[32m     17\u001b[39m content3 = f.read()\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeek -10 from end, Read: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent3\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, Current position: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.tell()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# Output: 'wxyz', 36 (end of file)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: TextIOWrapper.seek() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "# Create a sample file with known content and length\n",
    "with open('seek_tell_example.txt', 'w') as f:\n",
    "   f.write('0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "print(f\"Content of 'seek_tell_example.txt': '0123456789abcdefghijklmnopqrstuvwxyz'\")\n",
    "\n",
    "with open('seek_tell_example.txt', 'r') as f:\n",
    "   print(f\"Initial position: {f.tell()}\") # Output: 0\n",
    "\n",
    "   content1 = f.read(5) # Read first 5 characters\n",
    "   print(f\"Read: '{content1}', Current position: {f.tell()}\") # Output: '01234', 5\n",
    "\n",
    "   f.seek(10) # Move to 10th byte from beginning\n",
    "   content2 = f.read(5)\n",
    "   print(f\"Seek to 10, Read: '{content2}', Current position: {f.tell()}\") # Output: 'abcde', 15\n",
    "\n",
    "   f.seek(-10, whence = os.SEEK_END) # Move 10 bytes back from the end\n",
    "   content3 = f.read()\n",
    "   print(f\"Seek -10 from end, Read: '{content3}', Current position: {f.tell()}\") # Output: 'wxyz', 36 (end of file)\n",
    "\n",
    "   f.seek(0) # Go back to the beginning\n",
    "   print(f\"After seeking to beginning, Current position: {f.tell()}\") # Output: 0\n",
    "\n",
    "# Clean up the dummy file\n",
    "if os.path.exists('seek_tell_example.txt'):\n",
    "   os.remove('seek_tell_example.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295a23f-3da2-4104-b898-bb803755a630",
   "metadata": {},
   "source": [
    "While common reading methods like read() and readlines() abstract away the intricacies of the file pointer, seek() and tell() provide direct, byte-level control. This indicates that these methods are not intended for everyday text file operations but are indispensable for specific, more advanced use cases. For instance, they are crucial when parsing custom binary file formats that have a precise internal structure (e.g., image headers, compressed archives), where jumping to exact byte offsets is necessary. They are also valuable for implementing file indexing, allowing for quick navigation to specific sections of a large file without loading the entire content into memory. Furthermore, in scenarios like resuming interrupted downloads or data transfers, knowing the last written position (tell()) enables a program to seek() to that exact point and continue writing. These functions are powerful tools for optimizing file access and handling complex file structures that extend beyond simple line-by-line or full-content text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455fb39-2380-4d93-ba8c-a57d40067aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af437e4c-7722-4950-9afc-10ee7e0db359",
   "metadata": {},
   "source": [
    "# Module 6: Working with Structured Data: CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c272e-eacb-49fe-acdf-403a5e4347cb",
   "metadata": {},
   "source": [
    "CSV (Comma-Separated Values) files represent a ubiquitous format for storing tabular data, making them a common sight in data exchange. Python's built-in csv module significantly simplifies the process of interacting with these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21acf6ac-f9e2-4e3f-b951-b63211c66d5d",
   "metadata": {},
   "source": [
    "## What is a CSV File? (Comma-Separated Values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82282ef-7a19-48ce-8576-78e83f9b7b0d",
   "metadata": {},
   "source": [
    "A CSV file is essentially a plain-text file that organizes data in a tabular structure, much like a spreadsheet. Each line within the file typically corresponds to a row in a table, and the individual values within that row are separated by a specific character, most commonly a comma. This delimiter gives the format its name: \"comma-separated values.\" Often, the very first line of a CSV file serves as a header row, containing descriptive names for each column, which helps in understanding the data below.\n",
    "\n",
    "Consider the following example of a people.csv file:\n",
    "*  name,age,city\n",
    "*  Alice,30,New York\n",
    "*  Bob,25,San Francisco\n",
    "*  Charlie,35,London\n",
    "\n",
    "In this example, 'name', 'age', and 'city' are the column headers, and each subsequent line represents a record with values separated by commas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ba0ad-1ccc-4925-981f-f44d5595b1b5",
   "metadata": {},
   "source": [
    "## The csv Module: Your Tool for Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e9b9e-cf4a-4246-9e0f-d8bde5c39348",
   "metadata": {},
   "source": [
    "Python's standard library includes the csv module, which provides robust and convenient functionality for reading from and writing to CSV files. This module is designed to handle the various complexities inherent in the CSV format, such as values containing the delimiter character (which often require quoting), and different line ending conventions. By abstracting these details, the csv module makes it significantly easier to work with tabular data compared to manually parsing strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3b614-0de6-4ff9-88fc-22058b8894af",
   "metadata": {},
   "source": [
    "### Reading CSV Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141ccaeb-daf6-42a4-979e-b7f000a73ff8",
   "metadata": {},
   "source": [
    "The csv module offers two primary ways to read data from CSV files, catering to different preferences for data access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa2235-327d-4bf6-8c9f-b33d18981819",
   "metadata": {},
   "source": [
    "#### csv.reader: Getting Rows as Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a577935b-d2ea-4cae-b5f4-dfcc73453880",
   "metadata": {},
   "source": [
    "The csv.reader object allows for iterating over lines in a CSV file, with each row being returned as a list of strings. This method is straightforward and suitable when the order of columns is known and consistent, or when accessing data by numerical index is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47578102-a837-4c1e-8962-abceb967b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Reading 'people.csv' with csv.reader ---\n",
      "Column names: name, age, city\n",
      "\t['Alice', '30', 'New York'] is ['Alice', '30', 'New York'] years old and lives in ['Alice', '30', 'New York'].\n",
      "\t['Bob', '25', 'San Francisco'] is ['Bob', '25', 'San Francisco'] years old and lives in ['Bob', '25', 'San Francisco'].\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Create a sample CSV file for demonstration\n",
    "csv_content = \"\"\"name,age,city\n",
    "Alice,30,New York\n",
    "Bob,25,San Francisco\"\"\"\n",
    "with open('people.csv', 'w', newline='') as f: # newline='' is crucial for CSV handling\n",
    "   f.write(csv_content)\n",
    "\n",
    "# Reading with csv.reader\n",
    "print(\"--- Reading 'people.csv' with csv.reader ---\")\n",
    "with open('people.csv', 'r', newline='') as csv_file:\n",
    "   csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "   line_count = 0\n",
    "   for row in csv_reader:\n",
    "       if line_count == 0:\n",
    "           print(f'Column names: {\", \".join(row)}')\n",
    "       else:\n",
    "           print(f'\\t{row} is {row} years old and lives in {row}.')\n",
    "       line_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f8af3-ff59-4121-88a7-50b4302e933a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed152a4e-1fb7-4147-9c03-d275fb9c62cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19ca30-b896-4cae-9aa0-df2091a7f9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e06eb-ecd5-47bc-9159-5f6f8ccce5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "675630a9-be8c-40b7-a8d1-950e742ba22b",
   "metadata": {},
   "source": [
    "# DISCONTINUED (CSV AND JSON FILE HANDLING IN SEPERATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
